{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T07:00:54.648601Z",
     "start_time": "2026-01-06T07:00:52.264614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import certifi\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = os.environ[\"SSL_CERT_FILE\"]\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "import yaml\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.dataset import get_dataloaders\n",
    "from src.evaluation import TrainingMonitor, Evaluator\n",
    "from src.utils import set_seed, get_device, save_samples, CheckpointManager, print_model_summary\n",
    "\n",
    "config_path = PROJECT_ROOT / 'config' / 'config.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "device = get_device()\n",
    "set_seed(config['training'].get('seed', 42))\n",
    "\n",
    "IMAGE_SIZE = config['data'].get('image_size', 256)\n",
    "BATCH_SIZE = config['training'].get('batch_size', 1)\n",
    "EPOCHS = config['training'].get('epochs', 200)\n",
    "LR = float(config['training'].get('learning_rate', 2e-4))\n",
    "BETAS = tuple(config['training'].get('betas', [0.5, 0.999]))\n",
    "\n",
    "LAMBDA_CYCLE = 10.0\n",
    "LAMBDA_ID = 5.0\n",
    "POOL_SIZE = 50\n",
    "\n",
    "MODEL_NAME = 'cyclegan'\n",
    "OUTPUT_BASE = PROJECT_ROOT / 'data' / MODEL_NAME\n",
    "CHECKPOINT_DIR = OUTPUT_BASE / config['outputs'].get('checkpoints', 'outputs/checkpoints')\n",
    "SAMPLES_DIR = OUTPUT_BASE / config['outputs'].get('samples', 'outputs/generated_images')\n",
    "LOGS_DIR = OUTPUT_BASE / config['outputs'].get('logs', 'outputs/logs')\n",
    "REPORTS_DIR = OUTPUT_BASE / config['outputs'].get('reports', 'outputs/reports')\n",
    "\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SAMPLES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "50996360e52002ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-06T07:00:55.755475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loaders_apple = get_dataloaders(domain='apple', batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, paired=False, preload=True)\n",
    "loaders_orange = get_dataloaders(domain='orange', batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, paired=False, preload=True)\n",
    "\n",
    "train_loader_apple = loaders_apple['train']\n",
    "train_loader_orange = loaders_orange['train']\n",
    "val_loader_apple = loaders_apple['val']\n",
    "val_loader_orange = loaders_orange['val']\n",
    "\n",
    "print(f\"Train batches - Apple: {len(train_loader_apple)}, Orange: {len(train_loader_orange)}\")"
   ],
   "id": "b8533636109d05a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading apple (imageA) from HuggingFace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1019 images for train split.\n",
      "Preloading apple train...\n",
      "Preloaded 1019 images\n",
      "Loading apple (imageA) from HuggingFace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 266 images for test split.\n",
      "Preloading apple val...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),\n",
    "            nn.InstanceNorm2d(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc=3, output_nc=3, ngf=64, n_blocks=9):\n",
    "        super().__init__()\n",
    "\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=True),\n",
    "            nn.InstanceNorm2d(ngf),\n",
    "            nn.ReLU(True)\n",
    "        ]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2 ** i\n",
    "            model += [\n",
    "                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=True),\n",
    "                nn.InstanceNorm2d(ngf * mult * 2),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "\n",
    "        mult = 2 ** n_downsampling\n",
    "        for _ in range(n_blocks):\n",
    "            model += [ResNetBlock(ngf * mult)]\n",
    "\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(ngf * mult, ngf * mult // 2, kernel_size=3, stride=2, padding=1, output_padding=1, bias=True),\n",
    "                nn.InstanceNorm2d(ngf * mult // 2),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc=3, ndf=64, n_layers=3):\n",
    "        super().__init__()\n",
    "\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        mult = 1\n",
    "        for i in range(1, n_layers):\n",
    "            mult_prev = mult\n",
    "            mult = min(2 ** i, 8)\n",
    "            model += [\n",
    "                nn.Conv2d(ndf * mult_prev, ndf * mult, kernel_size=4, stride=2, padding=1, bias=True),\n",
    "                nn.InstanceNorm2d(ndf * mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        mult_prev = mult\n",
    "        mult = min(2 ** n_layers, 8)\n",
    "        model += [\n",
    "            nn.Conv2d(ndf * mult_prev, ndf * mult, kernel_size=4, stride=1, padding=1, bias=True),\n",
    "            nn.InstanceNorm2d(ndf * mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        model += [nn.Conv2d(ndf * mult, 1, kernel_size=4, stride=1, padding=1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class ImagePool:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        self.num_imgs = 0\n",
    "        self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            image = torch.unsqueeze(image.data, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs += 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                if random.random() > 0.5:\n",
    "                    idx = random.randint(0, self.pool_size - 1)\n",
    "                    tmp = self.images[idx].clone()\n",
    "                    self.images[idx] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return torch.cat(return_images, 0)\n",
    "\n",
    "\n",
    "def set_requires_grad(nets, requires_grad=False):\n",
    "    if not isinstance(nets, list):\n",
    "        nets = [nets]\n",
    "    for net in nets:\n",
    "        if net is not None:\n",
    "            for param in net.parameters():\n",
    "                param.requires_grad = requires_grad"
   ],
   "id": "3b694231e3eb9854",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "G_apple2monet = Generator().to(device)\n",
    "G_orange2photo = Generator().to(device)\n",
    "\n",
    "D_apple = Discriminator().to(device)\n",
    "D_orange = Discriminator().to(device)\n",
    "\n",
    "print_model_summary(G_apple2monet, 'Generator')\n",
    "print_model_summary(D_apple, 'Discriminator')\n",
    "\n",
    "opt_G = Adam(itertools.chain(G_apple2monet.parameters(), G_orange2photo.parameters()), lr=LR, betas=BETAS)\n",
    "opt_D_apple = Adam(D_apple.parameters(), lr=LR, betas=BETAS)\n",
    "opt_D_orange = Adam(D_orange.parameters(), lr=LR, betas=BETAS)\n",
    "\n",
    "def lambda_rule(epoch):\n",
    "    decay_start = EPOCHS // 2\n",
    "    return 1.0 - max(0, epoch - decay_start) / (EPOCHS - decay_start + 1)\n",
    "\n",
    "sched_G = lr_scheduler.LambdaLR(opt_G, lr_lambda=lambda_rule)\n",
    "sched_D_apple = lr_scheduler.LambdaLR(opt_D_apple, lr_lambda=lambda_rule)\n",
    "sched_D_orange = lr_scheduler.LambdaLR(opt_D_orange, lr_lambda=lambda_rule)\n",
    "\n",
    "pool_apple = ImagePool(POOL_SIZE)\n",
    "pool_orange = ImagePool(POOL_SIZE)\n",
    "\n",
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()\n",
    "\n",
    "checkpoint_manager = CheckpointManager(checkpoint_dir=str(CHECKPOINT_DIR), model_name=MODEL_NAME)\n",
    "start_epoch = 0"
   ],
   "id": "1ddcd3257852a8d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    monitor = TrainingMonitor(model_name=MODEL_NAME, log_dir=str(LOGS_DIR))\n",
    "    monitor.start_training()\n",
    "\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        if len(train_loader_apple) > len(train_loader_orange):\n",
    "            iter_orange = itertools.cycle(train_loader_orange)\n",
    "            iter_apple = iter(train_loader_apple)\n",
    "        else:\n",
    "            iter_apple = itertools.cycle(train_loader_apple)\n",
    "            iter_orange = iter(train_loader_orange)\n",
    "\n",
    "        num_batches = max(len(train_loader_apple), len(train_loader_orange))\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            real_apple = next(iter_apple)[0].to(device)\n",
    "            real_orange = next(iter_orange)[0].to(device)\n",
    "\n",
    "            fake_orange = G_apple2monet(real_apple)\n",
    "            rec_apple = G_orange2photo(fake_orange)\n",
    "            fake_apple = G_orange2photo(real_orange)\n",
    "            rec_orange = G_apple2monet(fake_apple)\n",
    "\n",
    "            if LAMBDA_ID > 0:\n",
    "                idt_apple = G_orange2photo(real_apple)\n",
    "                idt_orange = G_apple2monet(real_orange)\n",
    "\n",
    "            set_requires_grad([D_apple, D_orange], False)\n",
    "            opt_G.zero_grad()\n",
    "\n",
    "            loss_GAN_apple2monet = criterion_GAN(D_orange(fake_orange), torch.ones_like(D_orange(fake_orange)))\n",
    "            loss_GAN_orange2photo = criterion_GAN(D_apple(fake_apple), torch.ones_like(D_apple(fake_apple)))\n",
    "\n",
    "            loss_cycle_apple = criterion_cycle(rec_apple, real_apple) * LAMBDA_CYCLE\n",
    "            loss_cycle_orange = criterion_cycle(rec_orange, real_orange) * LAMBDA_CYCLE\n",
    "\n",
    "            if LAMBDA_ID > 0:\n",
    "                loss_id_apple = criterion_identity(idt_apple, real_apple) * LAMBDA_ID\n",
    "                loss_id_orange = criterion_identity(idt_orange, real_orange) * LAMBDA_ID\n",
    "                loss_G = loss_GAN_apple2monet + loss_GAN_orange2photo + loss_cycle_apple + loss_cycle_orange + loss_id_apple + loss_id_orange\n",
    "            else:\n",
    "                loss_G = loss_GAN_apple2monet + loss_GAN_orange2photo + loss_cycle_apple + loss_cycle_orange\n",
    "\n",
    "            loss_G.backward()\n",
    "            opt_G.step()\n",
    "\n",
    "            set_requires_grad(D_apple, True)\n",
    "            opt_D_apple.zero_grad()\n",
    "            fake_apple_pool = pool_apple.query(fake_apple.detach())\n",
    "            loss_D_apple_real = criterion_GAN(D_apple(real_apple), torch.ones_like(D_apple(real_apple)))\n",
    "            loss_D_apple_fake = criterion_GAN(D_apple(fake_apple_pool), torch.zeros_like(D_apple(fake_apple_pool)))\n",
    "            loss_D_apple = (loss_D_apple_real + loss_D_apple_fake) * 0.5\n",
    "            loss_D_apple.backward()\n",
    "            opt_D_apple.step()\n",
    "\n",
    "            set_requires_grad(D_orange, True)\n",
    "            opt_D_orange.zero_grad()\n",
    "            fake_orange_pool = pool_orange.query(fake_orange.detach())\n",
    "            loss_D_orange_real = criterion_GAN(D_orange(real_orange), torch.ones_like(D_orange(real_orange)))\n",
    "            loss_D_orange_fake = criterion_GAN(D_orange(fake_orange_pool), torch.zeros_like(D_orange(fake_orange_pool)))\n",
    "            loss_D_orange = (loss_D_orange_real + loss_D_orange_fake) * 0.5\n",
    "            loss_D_orange.backward()\n",
    "            opt_D_orange.step()\n",
    "\n",
    "            monitor.log_loss('loss_G', loss_G.item())\n",
    "            monitor.log_loss('loss_D', (loss_D_apple + loss_D_orange).item())\n",
    "            monitor.log_loss('loss_cycle', (loss_cycle_apple + loss_cycle_orange).item())\n",
    "            if LAMBDA_ID > 0:\n",
    "                monitor.log_loss('loss_identity', (loss_id_apple + loss_id_orange).item())\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{EPOCHS}] Batch [{i}/{num_batches}] \"\n",
    "                      f\"Loss_G: {loss_G.item():.4f} Loss_D: {(loss_D_apple + loss_D_orange).item():.4f}\")\n",
    "\n",
    "            if i % 200 == 0:\n",
    "                with torch.no_grad():\n",
    "                    samples = [real_apple[0], fake_orange[0], rec_apple[0], real_orange[0], fake_apple[0], rec_orange[0]]\n",
    "                    titles = ['Photo', 'Fake Monet', 'Rec Photo', 'Monet', 'Fake Photo', 'Rec Monet']\n",
    "                    save_samples(samples, SAMPLES_DIR / f\"epoch_{epoch}_batch_{i}.png\", nrow=3, titles=titles)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        monitor.log_epoch_time(epoch_time)\n",
    "        monitor.log_learning_rate(sched_G.get_last_lr()[0])\n",
    "\n",
    "        if epoch == start_epoch:\n",
    "            print(f\"Estimated total time: {epoch_time * EPOCHS / 3600:.1f} hours\")\n",
    "\n",
    "        sched_G.step()\n",
    "        sched_D_apple.step()\n",
    "        sched_D_orange.step()\n",
    "\n",
    "        checkpoint_manager.save(\n",
    "            epoch,\n",
    "            G_apple2monet=G_apple2monet, G_orange2photo=G_orange2photo,\n",
    "            D_apple=D_apple, D_orange=D_orange,\n",
    "            opt_G=opt_G, opt_D_apple=opt_D_apple, opt_D_orange=opt_D_orange\n",
    "        )\n",
    "\n",
    "    monitor.save()"
   ],
   "id": "dd3ee96a0055d9fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train()",
   "id": "21a65c46bafe1e3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate():\n",
    "    G_apple2monet.eval()\n",
    "    G_orange2photo.eval()\n",
    "\n",
    "    evaluator = Evaluator(model_name=MODEL_NAME, device=device, output_dir=str(REPORTS_DIR))\n",
    "\n",
    "    print(\"Computing real Monet statistics for FID...\")\n",
    "    evaluator.set_real_data(val_loader_orange)\n",
    "\n",
    "    print(\"Evaluating Photo→Monet translation...\")\n",
    "    result = evaluator.evaluate(\n",
    "        generator=G_apple2monet,\n",
    "        content_loader=val_loader_apple,\n",
    "        num_samples=min(500, len(val_loader_apple.dataset))\n",
    "    )\n",
    "\n",
    "    result_path = REPORTS_DIR / f\"{MODEL_NAME}_evaluation.json\"\n",
    "    result.save(str(result_path))\n",
    "    print(f\"Evaluation saved to {result_path}\")\n",
    "\n",
    "    print(\"Generating comparison samples...\")\n",
    "    with torch.no_grad():\n",
    "        sample_apples = next(iter(val_loader_apple)).to(device)\n",
    "        sample_oranges = next(iter(val_loader_orange)).to(device)\n",
    "\n",
    "        fake_oranges = G_apple2monet(sample_apples)\n",
    "        fake_apples = G_orange2photo(sample_oranges)\n",
    "        rec_apples = G_orange2photo(fake_oranges)\n",
    "        rec_oranges = G_apple2monet(fake_apples)\n",
    "\n",
    "        samples_p2m = [sample_apples[0], fake_oranges[0], rec_apples[0]]\n",
    "        titles_p2m = ['Photo', '→ Monet', '→ Photo']\n",
    "        save_samples(samples_p2m, SAMPLES_DIR / \"final_apple2monet_cycle.png\", nrow=3, titles=titles_p2m)\n",
    "\n",
    "        samples_m2p = [sample_oranges[0], fake_apples[0], rec_oranges[0]]\n",
    "        titles_m2p = ['Monet', '→ Photo', '→ Monet']\n",
    "        save_samples(samples_m2p, SAMPLES_DIR / \"final_orange2photo_cycle.png\", nrow=3, titles=titles_m2p)\n",
    "\n",
    "        n_samples = min(4, sample_apples.size(0))\n",
    "        grid_samples = []\n",
    "        grid_titles = []\n",
    "        for i in range(n_samples):\n",
    "            grid_samples.extend([sample_apples[i], fake_oranges[i], rec_apples[i]])\n",
    "            grid_titles.extend([f'Photo {i+1}', f'Fake Monet {i+1}', f'Rec Photo {i+1}'])\n",
    "        save_samples(grid_samples, SAMPLES_DIR / \"final_grid.png\", nrow=3, titles=grid_titles)\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Evaluation Summary: {MODEL_NAME}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"FID Score: {result.fid_score:.2f}\")\n",
    "    print(f\"SSIM Score: {result.ssim_score:.4f}\")\n",
    "    print(f\"Total Parameters: {result.total_params:,}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    G_apple2monet.train()\n",
    "    G_orange2photo.train()\n",
    "\n",
    "    return result"
   ],
   "id": "cc4e22d53d312c12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result = evaluate()",
   "id": "17a2a5ed9392e785",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fe813bf254b0152d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
